{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a30967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define AttributeError exception for get_text\n",
    "\n",
    "def txt_ex(i,select,class_):\n",
    "    try:\n",
    "        return i.find(select,class_).get_text().strip()\n",
    "    except AttributeError as Err:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66717bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define AttributeError exception for links\n",
    "def link_ex(i):\n",
    "    try:\n",
    "        return i.get('href')\n",
    "    except AttributeError as Err:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a56077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define AttributeError exception for find_alls\n",
    "def finds_all(i,select,class_):\n",
    "    try:\n",
    "        return i.find_all(select,class_)\n",
    "    except AttributeError as Err:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pulling data from website\n",
    "\n",
    "def pull_data(URL):\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    page=requests.get(URL, headers=headers)\n",
    "\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "    \n",
    "    return soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[] \n",
    "\n",
    "#Scrape pages 1 to 20 of the website\n",
    "\n",
    "for i in range (1,21):\n",
    "    \n",
    "    URL=f'https://www.etsy.com/c/books-movies-and-music/books/childrens-books?ref=pagination&page={i}' # URL address for children book at etsy \n",
    "    \n",
    "    soup=pull_data(URL) #pull html data of the url\n",
    "    ols=soup.find(\"ol\")\n",
    "    lis=ols.find_all('li')\n",
    "    \n",
    "    for link in lis:\n",
    "        \n",
    "        # Extract title of the product\n",
    "        title=txt_ex(link,'h3',\"wt-text-caption v2-listing-card__title wt-text-truncate\")\n",
    "        \n",
    "        # Extract the links of product page\n",
    "        a_s=link.find('a')\n",
    "        links=link_ex(a_s) \n",
    "        \n",
    "        # pull html data of individual product page\n",
    "        soup=pull_data(links) \n",
    "        \n",
    "        #Extract the price of the product with removing new line to convert it to a single line\n",
    "        price=txt_ex(soup, 'p',\"wt-text-title-03 wt-mr-xs-1\") \n",
    "        char_to_remove= \"\\n  \"\n",
    "        price = price.replace(char_to_remove, \",\")\n",
    "        \n",
    "        #Extract Shop name of the product\n",
    "        shop=txt_ex(soup,'span', \"wt-text-title-small\")\n",
    "        \n",
    "        # Extract the overall_star of the product\n",
    "        overall_star=txt_ex(soup, 'span', \"wt-display-inline-block wt-mr-xs-1\")\n",
    "        \n",
    "        # Extract the individual star rating, reviewe, date of the review \n",
    "        divs=soup.find('div', class_=\"wt-pl-xs-0 wt-mb-xs-2 wt-mb-lg-6\")\n",
    "        divs2=finds_all(divs,'div',\"wt-grid__item-xs-12\")\n",
    "        if divs2 is not None:\n",
    "            for reveiw in divs2:\n",
    "                star=txt_ex(reveiw,'span', \"wt-screen-reader-only\")\n",
    "                reviews=txt_ex(reveiw,'p',\"wt-text-truncate--multi-line\")\n",
    "                date=txt_ex(reveiw,'p',\"wt-text-caption wt-text-gray\")\n",
    "                char_to_remove= \"\\n  \"\n",
    "                date = date.replace(char_to_remove, \",\")\n",
    "                urls.append([title, price, shop, overall_star, star, reviews, date, links]) # Append all datain a list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ee6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file and emport all data in the file\n",
    "df=pd.DataFrame(urls, columns=['Title', 'Price', 'Shop_name', 'Overall_star', 'Star_rating', 'Review', 'Customer_date', 'Product_links'])\n",
    "df.to_csv('Etsy_Reveiw_Data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df=pd.read_csv(\"C:/Users/ashpi/Etsy_Reveiw_Data_2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481dbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
